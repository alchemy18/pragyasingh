<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Pragya Singh</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons --->
  <link href="assets/img/favicon.jfif" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <style>
    .about-content {
      margin-top: 20px;
    }
    .skill-badge {
      display: inline-block;
      background-color: #f8f9fa;
      color: #0563bb;
      border: 1px solid #0563bb;
      border-radius: 15px;
      padding: 4px 12px;
      margin: 4px;
      font-size: 0.9rem;
    }
    .info-box {
      padding: 15px;
      border-radius: 8px;
      margin-bottom: 15px;
      background-color: #f8f9fa;
      box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .info-box h5 {
      color: #0563bb;
      font-weight: 600;
      margin-bottom: 10px;
    }
    .publication-item {
      margin-bottom: 30px;
      padding-bottom: 20px;
      border-bottom: 1px solid #e9ecef;
    }
    .publication-item:last-child {
      border-bottom: none;
    }
    .publication-title {
      margin-bottom: 5px;
    }
    .publication-title a {
      color: #0563bb;
      font-weight: 600;
    }
    .publication-title a:hover {
      text-decoration: underline;
    }
    .publication-meta {
      color: #6c757d;
      font-style: italic;
      margin-bottom: 10px;
    }
    .btn-cv {
      background-color: #0563bb;
      color: #fff;
      border-radius: 25px;
      padding: 8px 25px;
      transition: all 0.3s;
      margin-top: 20px;
    }
    .btn-cv:hover {
      background-color: #0e7eda;
      transform: translateY(-2px);
      box-shadow: 0 5px 15px rgba(0,0,0,0.1);
    }
    .research-highlight {
      background-color: rgba(5, 99, 187, 0.05);
      border-left: 3px solid #0563bb;
      padding: 15px;
      margin: 20px 0;
      border-radius: 0 5px 5px 0;
    }
  </style>
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/favicon.jfif" alt="profile picture" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Pragya Singh</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://www.linkedin.com/in/pragya-singh-438508113" class="linkedin"><i class="bx bxl-linkedin"></i></a>
          <a href="https://scholar.google.com/citations?user=fxfhl98AAAAJ&hl=en" class="iconify"><i class="bi bi-google"></i></a>
          <a href="https://www.youtube.com/channel/UCkpL9eii6g4SpweK_znr15A" class="iconify"><i class="bx bxl-youtube"></i></a>
          <a href="https://twitter.com/Pragya18rathore" class="instagram"><i class="bi bi-twitter"></i></a>
          <a href="https://github.com/alchemy18" class="github"><i class="bx bxl-github"></i></a>
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Publications</span></a></li>
          <li><a href="#awards" class="nav-link scrollto"><i class="bx bx-award"></i> <span>Awards</span></a></li>
          <li><a href="#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
        </ul>
      </nav><!-- .nav-menu -->
    </div>
  </header><!-- End Header -->

  <!-- ======= Hero Section ======= -->
  <section id="hero" class="d-flex flex-column justify-content-center align-items-center" style="background: url('assets/Background.png') top center; background-size: cover;">
    <div class="hero-container" data-aos="fade-in">
      <h1>Pragya Singh</h1>
      <p>I'm <span class="typed" data-typed-items="PhD Scholar, Researcher, Thinker, Happy Soul, Always Curious"></span></p>
    </div>
  </section><!-- End Hero -->

  <main id="main">

    <!-- ======= About Section ======= -->
    <section id="about" class="about">
      <div class="container">

        <div class="section-title">
          <h2>About</h2>
        </div>

        <div class="row">
          <div class="col-lg-4" data-aos="fade-right">
            <img src="assets/img/profile.jpeg" class="img-fluid shadow rounded" alt="profile picture">
            <div class="text-center">
              <a href="assets/pragya_singh_phd__cv.pdf" class="btn btn-cv" download><i class="bi bi-file-earmark-text me-2"></i>Download CV</a>
            </div>
          </div>
          <div class="col-lg-8 pt-4 pt-lg-0" data-aos="fade-left">
            <h3>PhD Candidate at IIIT-Delhi</h3>
            
            <div class="research-highlight">
              <p>
                I'm a fourth-year Ph.D. candidate at IIIT-Delhi, exploring the fascinating intersection where technology meets human emotions. My research bridges multiple disciplines: artificial intelligence, ubiquitous computing, human-computer interaction, and healthcare.
              </p>
              <p>
                Imagine a world where your wearable device not only tracks your steps but understands your emotional state. I'm developing predictive models that decode the subtle language of physiological signals—your heartbeat, skin conductance, body temperature—to assess mental well-being in everyday settings. This interdisciplinary approach allows me to build AI systems that are both technically robust and deeply human-centered.
              </p>
              <p>
                What makes my work unique is its focus on the complexities of emotion data through an HCI lens. By understanding how humans experience, express, and report emotions, I design algorithms that can recognize emotional patterns more accurately in real-world environments—where data is messy, context matters, and individual differences abound.
              </p>
            </div>
            
            <div class="about-content">
              <h5>Research Interests</h5>
              <div>
                <span class="skill-badge">HCAI</span>
                <span class="skill-badge">AI for Healthcare</span>
                <span class="skill-badge">Emotion Recognition</span>
                <span class="skill-badge">Representation Learning</span>
                <span class="skill-badge">Multimodal Learning</span>
                <span class="skill-badge">Data-centric AI</span>
                <span class="skill-badge">Responsible AI</span>
              </div>
            </div>
            
            <div class="row mt-4">
              <div class="col-md-6">
                <div class="info-box">
                  <h5><i class="bi bi-check2-square me-2"></i>Professional Activities</h5>
                  <p class="mb-0"><strong>Reviewer:</strong> CHI, CSCW, IMWUT, UbiComp, Percom, WiML workshop (Neurips)</p>
                  <p><strong>TA:</strong> Interactive Systems, Mobile Computing, Research Methods, Computer Networks</p>
                </div>
              </div>
              <div class="col-md-6">
                <div class="info-box">
                  <h5><i class="bi bi-people me-2"></i>Volunteering</h5>
                  <p class="mb-0">ACM Compass 2024 Organizing Team</p>
                  <p class="mb-0">TinyML India Organizing Team</p>
                  <p class="mb-0"><strong>Program Co-chair:</strong> AutoMLPerSys 2025</p>
                  <p class="mb-0"><strong>Steering Committee:</strong> AutoMLPerSys 2024</p>
                </div>
              </div>
            </div>
          </div>
        </div>

      </div>
    </section><!-- End About Section -->

    <!-- ======= Publications Section ======= -->
    <section id="portfolio" class="portfolio section-bg">
      <div class="container">

        <div class="section-title">
          <h2>Publications</h2>
        </div>

        <div class="row" data-aos="fade-up">
          <div class="col-lg-12">
            
            <div class="publication-item">
              <h4 class="publication-title">
                <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/1cba8502063fab9df252a63968691768-Paper-Datasets_and_Benchmarks_Track.pdf">EEVR: A Dataset of Paired Physiological Signals and Textual Descriptions for Joint Emotion Representation Learnings</a>
              </h4>
              <p class="publication-meta">NeurIPS 2024, Dataset and Benchmark Track (September 2024)</p>
              <p><strong>Authors:</strong> Pragya Singh, Ritvik Budhiraja, Ankush Gupta, Anshul Goswami, Mohan Kumar, Pushpendra Singh</p>
              <p>The EEVR (Emotion Elicitation in Virtual Reality) dataset is a novel resource created for language-supervision-based pre-training and emotion recognition tasks, such as classifying valence and arousal. It includes high-quality physiological signals paired with qualitative textual descriptions of emotions. We evaluated the dataset using the Contrastive Language Signal Pre-training (CLSP) method, which combines physiological signals with self-reported emotional annotations. This approach significantly improved performance in emotion recognition, with a 20% increase in arousal classification and a 10% increase in valence classification.</p>
            </div>
            
            <div class="publication-item">
              <h4 class="publication-title">
                <a href="https://arxiv.org/pdf/2503.19636">Translating Emotions to Annotations: A Participant's Perspective of Physiological Emotion Data Collection</a>
              </h4>
              <p class="publication-meta">CSCW 2024 (September 2024)</p>
              <p><strong>Authors:</strong> Pragya Singh, Ritvik Budhiraja, Mohan Kumar, Pushpendra Singh</p>
              <p>Physiological signals hold immense potential for ubiquitous emotion monitoring, presenting numerous applications in emotion recognition. However, harnessing this potential is hindered by significant challenges, particularly in the collection of annotations that align with physiological changes since the process hinges heavily on human participants. In this work, we set out to study the perspectives of human participants involved in the emotion data collection procedure using 360° virtual reality video stimulus followed by semi-structured interviews.</p>
            </div>
            
            <div class="publication-item">
              <h4 class="publication-title">
                <a href="https://programs.sigchi.org/chi/2025/program/content/188903">"But I Won't Say That It Was Bad Seeing a Real Vagina": Understanding Perspectives toward Learning Sensitive-Critical Health Topic</a>
              </h4>
              <p class="publication-meta">CHI 2025 (January 2025)</p>
              <p><strong>Authors:</strong> Sara Moin, Manshul Belani, Pragya Singh, Nishtha Phutela, Pushpendra Singh</p>
              <p>In India, topics related to sexual and reproductive health (SRH) are rarely discussed openly due to stigma. To understand the attitudes towards SRH, we designed a Cervical cancer awareness tutorial in Virtual Reality and collected data from 66 participants across genders and life stages through interviews, self-reported emotions, and physiological sensor data. Our findings revealed an acute lack of knowledge about self-body anatomy and a need for creating health literacy.</p>
            </div>
            
            <div class="publication-item">
              <h4 class="publication-title">
                <a href="https://arxiv.org/pdf/2406.14908">Can we say a cat is a cat? Understanding the challenges in annotating physiological signal-based emotion data</a>
              </h4>
              <p class="publication-meta">PhysioCHI, CHI 2024 Workshop (June 2024)</p>
              <p><strong>Authors:</strong> Pragya Singh, Mohan Kumar, Pushpendra Singh</p>
              <p>This paper presents a position discussion on the current technique of annotating physiological signal-based emotion data. Our discourse underscores the importance of adopting a nuanced understanding of annotation processes, paving the way for a more insightful exploration of the intricate relationship between physiological signals and human emotions.</p>
            </div>
            
            <div class="publication-item">
              <h4 class="publication-title">
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150311">Generating Tiny Deep Neural Networks for ECG Classification on MicroControllers</a>
              </h4>
              <p class="publication-meta">IEEE International Conference on Pervasive Computing, PerCom Industry Track 2023 (March 2023)</p>
              <p><strong>Authors:</strong> S. Mukhopadhyay, S. Dey, A. Ghose, Pragya Singh and P. Dasgupta</p>
              <p>This paper shows that Neural Architecture Search (NAS) can be used to generate tiny but accurate multi-objective models for classifying ECG signals. Our framework is the first of its kind for automatically generating a DNN for screening Atrial Fibrillation on an MCU. Moreover, our research shows that the proposed NAS finds more accurate tiny models than human-designed ones and is effective in enabling customized solutions for a resource-limited target platform.</p>
            </div>
            
          </div>
        </div>
      </div>
    </section><!-- End Publications Section -->
    
    <!-- ======= Awards Section ======= -->
    <section id="awards" class="services">
      <div class="container">

        <div class="section-title">
          <h2>Awards and Fellowships</h2>
        </div>

        <div class="row">
          <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up">
            <div class="icon"><i class="bi bi-award"></i></div>
            <h4 class="title">Chanakya Doctoral Fellowship</h4>
            <p class="description">From Ihub Anubhuti (August 2024)</p>
          </div>
          <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up" data-aos-delay="100">
            <div class="icon"><i class="bi bi-airplane"></i></div>
            <h4 class="title">Microsoft Conference Travel Grant</h4>
            <p class="description">For NeurIPS 2024 (September 2024)</p>
          </div>
          <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up" data-aos-delay="200">
            <div class="icon"><i class="bi bi-star"></i></div>
            <h4 class="title">Award Finalist</h4>
            <p class="description">For Poster Presentation at The Machine Learning Summer School in Okinawa 2024 (March 2024)</p>
          </div>
        </div>

      </div>
    </section><!-- End Awards Section -->

    <!-- ======= Contact Section ======= -->
    <section id="contact" class="contact">
      <div class="container">

        <div class="section-title">
          <h2>Contact</h2>
          <p>If our research interests align, I would be grateful to connect and collaborate on new ideas.</p>
        </div>

        <div class="row" data-aos="fade-in">

          <div class="col-lg-5 d-flex align-items-stretch">
            <div class="info">
              <div class="address">
                <i class="bi bi-geo-alt"></i>
                <h4>Location:</h4>
                <p>IIITD, Delhi, India</p>
              </div>

              <div class="email">
                <i class="bi bi-envelope"></i>
                <h4>Email:</h4>
                <p>pragyas@iiitd.ac.in</p>
                <p>pragyasingh18rathore@gmail.com</p>
              </div>
            

              <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d3504.8026265809!2d77.2709685!3d28.5456517!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x0%3A0x691393414902968e!2sIIIT-Delhi%20R%26D%20Building!5e0!3m2!1sen!2sin!4v1639315084076!5m2!1sen!2sin" frameborder="0" style="border:0; width: 100%; height: 290px;" allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </section><!-- End Contact Section -->
  </main><!-- End #main -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
