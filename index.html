<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Pragya Singh</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.jfif" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: iPortfolio - v3.7.0
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/profile_img.JPG" alt="profile picture" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Pragya Singh</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://www.linkedin.com/in/pragya-singh-438508113" class="linkedin"><i class="bx bxl-linkedin"></i></a>
          <a href="https://scholar.google.com/citations?user=fxfhl98AAAAJ&hl=en" class="iconify"><i class="bi bi-google"></i></a>
          <a href="https://www.youtube.com/channel/UCkpL9eii6g4SpweK_znr15A" class="iconify"><i class="bx bxl-youtube"></i></a>
          <a href="https://twitter.com/Pragya18rathore" class="instagram"><i class="bi bi-twitter"></i></a>
          <a href="https://github.com/alchemy18" class="github"><i class="bx bxl-github"></i></a>
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
          <li><a href="#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Publications</span></a></li>
          <li><a href="#awards" class="nav-link scrollto"><i class="bx bx-award"></i> <span>Awards</span></a></li>
          <li><a href="#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
        </ul>
      </nav><!-- .nav-menu -->
    </div>
  </header><!-- End Header -->

  <!-- ======= Hero Section ======= -->
  <section id="hero" class="d-flex flex-column justify-content-center align-items-center">
    <div class="hero-container" data-aos="fade-in">
      <h1>Pragya Singh</h1>
      <p>I'm <span class="typed" data-typed-items="PhD Scholar, Researcher, Thinker"></span></p>
    </div>
  </section><!-- End Hero -->

  <main id="main">

    <!-- ======= About Section ======= -->
    <section id="about" class="about">
      <div class="container">

        <div class="section-title">
          <h2>About</h2>
          <p>I am a fourth-year Ph.D. candidate at IIIT-Delhi, India. My research lies at the intersection of artificial intelligence, ubiquitous computing, human-computer interaction (HCI), and healthcare. My thesis focuses on developing predictive models for mental health assessment by leveraging physiological signals and other non-invasive data from wearable and mobile devices. Within my research, I aim to understand the emotion data from HCI perspectives to accommodate for complexities in emotion data and further design algorithms for emotion recognition in everyday settings.</p>
        </div>

        <div class="row">
          <div class="col-lg-4" data-aos="fade-right">
            <img src="assets/img/profile_img.JPG" class="img-fluid" alt="profile picture">
          </div>
          <div class="col-lg-8 pt-4 pt-lg-0 content" data-aos="fade-left">
            <h3>PhD Candidate</h3>
            <p class="fst-italic">
              <b>Research Interest</b>: HCAI, AI for Healthcare, Emotion Recognition, Representation Learning, Multimodal Learning, Data-centric AI
            </p>
            <div class="row">
              <div class="col-lg-6">
                <ul>
                  <li><i class="bi bi-chevron-right"></i> <strong>Email:</strong> <span>pragyas@iiitd.ac.in</span></li>
                  <li><i class="bi bi-chevron-right"></i> <strong>City:</strong> <span>New Delhi, India</span></li>
                  <li><i class="bi bi-chevron-right"></i> <strong>Skills:</strong> <p>Deep Learning, Machine Learning, Physiological Signal Processing, TinyML</p></li>
                  <li><i class="bi bi-chevron-right"></i> <strong>Reviewer:</strong> <p>CHI, CSCW, IMWUT, UbiComp, Percom, WiML workshop (Neurips)</p></li>
                </ul>
              </div>
              <div class="col-lg-6">
                <ul>
                  <li><i class="bi bi-chevron-right"></i> <strong>Volunteer:</strong> <p>ACM Compass 2024 Organizing Team, TinyML India Organizing Team, <b>Program Co-chair:</b> <a href="https://sites.google.com/view/automlpersys2025/">AutoMLPerSys 2025</a> & <b>Steering Committee:</b> <a href="https://sites.google.com/view/automlpersys2024/organizers">AutoMLPerSys 2024</a> (Co-located with PERCOM).</p></li>
                </ul>
              </div>
            </div>
          </div>
        </div>

      </div>
    </section><!-- End About Section -->

    <!-- ======= Resume Section ======= -->
    <section id="resume" class="resume">
      <div class="container">

        <div class="section-title">
          <h2>Resume</h2>   
        </div>

        <div class="row">
          <div class="col-lg-6" data-aos="fade-up">
            <h3 class="resume-title">Ph.D.</h3>
            <div class="resume-item pb-0">
              <h4>Pragya Singh</h4>
              <p><em>I'm currently pursuing Ph.D.at IIITD, India, under the guidance of <a href="https://www.iiitd.ac.in/pushpendra">Prof. Pushpendra Singh</a>, IIITD, India, and <a href="https://www.rit.edu/directory/mjkvcs-mohan-kumar">Prof. Mohan Kumar</a>, RIT, USA. 
              I work on <b>"Wearable AI for Mental Health in Everyday Settings using Human-Centric Approaches"</b>.</em></p>
              <h4>Started in August 2021</h4>
            </div>
            
            <h3 class="resume-title">Education</h3>
            <div class="resume-item">
              <h4>Doctor of Philosophy & M.Tech in Computer Science and Engineering (AI Specialization)</h4>
              <h5>2021-Present</h5>
              <p><em>Indraprastha Institute of Information Technology, New Delhi, India</em></p>
              <p>I am pursuing PhD in Department of Computer Science and Engineering along with M.Tech (AI Specialization). My thesis is directed towards interdisciplinary research at the intersection of Wearables, Efficient AI and mental health monitoring, management and
              diagnosis. Course-work: Machine Learning, Deep Learning, Bayesian Machine Learning, Reinforcement Learning, Interactive Systems, Algorithms. On-going GPA: 8.48%</p>
            </div>
            <div class="resume-item">
              <h4>Diploma in Embedded Systems Engineering</h4>
              <h5>2018 - 2019</h5>
              <p><em>Centre for Development of Advanced Computing (C-DAC), ACTS, Pune, India</em></p>
              <p>Course-work: C, C++, Embedded systems, Communication protocols, Android development. Percentage: 79.29%</p>
            </div>
            <div class="resume-item">
              <h4>B.Tech in Electronics and Communication Engineering</h4>
              <h5>2014 - 2018</h5>
              <p><em>Institute of Engineering and Technology, Dr. Ram Manohar Lohia, Awadh University, U.P, India</em></p>
              <p>Percentage: 78.3%</p>
            </div>
          </div>
          <div class="col-lg-6" data-aos="fade-up" data-aos-delay="100">
            <h3 class="resume-title">Professional Experience</h3>
            <div class="resume-item">
              <h4>Research Intern</h4>
              <h5>February 2022 - July 2022</h5>
              <p><em>Embedded Devices and Intelligent Systems Lab, TCS Research</em></p>
              <ul>
                <li>Worked on Platform-Aware Neural Architecture Search for ECG classification on wearables.</li>
                <li>Contributed in benchmarking for Tiny DNNs generation using Hardware aware NAS for the task of single lead ECG classification in wearables.</li>
                <li>Conducted a State-of-the-Art survey on NAS techniques for various tasks like image classification and object detection.</li>
              </ul>
            </div>
            <div class="resume-item">
              <h4>Embedded Systems Engineer (R & D)</h4>
              <h5>2020 - 2021</h5>
              <p><em>Lohia Mechatronik, Pune, India </em></p>
              <ul>
                <li>Developed and troubleshooted Baremetal Embedded software for manufacturing facilities.</li>
                <li>Worked on machine vision and sensor automation for manufacturing facilities.</li>
                <li>Automated induction motors and temperature-based actuators using CANopen and microcontrollers.</li>
              </ul>
            </div>
            <div class="resume-item">
              <h4>Embedded Software Engineer</h4>
              <h5>2019 - 2020</h5>
              <p><em>KPIT Technologies, Pune, India</em></p>
              <ul>
                <li>Configured complex device drivers, communication stacks, and diagnostic systems for classic AUTOSAR.</li>
                <li>Derived verification criteria and conducted MIL testing for Software components.</li>
              </ul>
            </div>
            
            <h3 class="resume-title">Teaching</h3>
            <div class="resume-item">
              <h4>Teaching Assistant</h4>
              <p><em>IIIT-Delhi</em></p>
              <ul>
                <li>Mobile Computing, Computer Networks, Research Methods, Interactive Systems (Best TA award)</li>
              </ul>
            </div>
          </div>
        </div>

      </div>
    </section><!-- End Resume Section -->

    <!-- ======= Publications Section ======= -->
    <section id="portfolio" class="portfolio section-bg">
      <div class="container">

        <div class="section-title">
          <h2>Publications</h2>
          
          <div class="publication-item">
            <h4><a href="#">EEVR: A Dataset of Paired Physiological Signals and Textual Descriptions for Joint Emotion Representation Learnings</a></h4>
            <p><em>NeurIPS 2024, Dataset and Benchmark Track (September 2024)</em></p>
            <p><strong>Authors:</strong> Pragya Singh, Ritvik Budhiraja, Ankush Gupta, Anshul Goswami, Mohan Kumar, Pushpendra Singh</p>
            <p>The EEVR (Emotion Elicitation in Virtual Reality) dataset is a novel resource created for language-supervision-based pre-training and emotion recognition tasks, such as classifying valence and arousal. It includes high-quality physiological signals paired with qualitative textual descriptions of emotions. We evaluated the dataset using the Contrastive Language Signal Pre-training (CLSP) method, which combines physiological signals with self-reported emotional annotations. This approach significantly improved performance in emotion recognition, with a 20% increase in arousal classification and a 10% increase in valence classification.</p>
          </div>
          
          <div class="publication-item">
            <h4><a href="#">Translating Emotions to Annotations: A Participant's Perspective of Physiological Emotion Data Collection</a></h4>
            <p><em>CSCW 2024 (September 2024)</em></p>
            <p><strong>Authors:</strong> Pragya Singh, Ritvik Budhiraja, Mohan Kumar, Pushpendra Singh</p>
            <p>Physiological signals hold immense potential for ubiquitous emotion monitoring, presenting numerous applications in emotion recognition. However, harnessing this potential is hindered by significant challenges, particularly in the collection of annotations that align with physiological changes since the process hinges heavily on human participants. In this work, we set out to study the perspectives of human participants involved in the emotion data collection procedure using 360° virtual reality video stimulus followed by semi-structured interviews.</p>
          </div>
          
          <div class="publication-item">
            <h4><a href="#">"But I Won't Say That It Was Bad Seeing a Real Vagina": Understanding Perspectives toward Learning Sensitive-Critical Health Topic</a></h4>
            <p><em>CHI 2025 (January 2025)</em></p>
            <p><strong>Authors:</strong> Sara Moin, Manshul Belani, Pragya Singh, Nishtha Phutela, Pushpendra Singh</p>
            <p>In India, topics related to sexual and reproductive health (SRH) are rarely discussed openly due to stigma. To understand the attitudes towards SRH, we designed a Cervical cancer awareness tutorial in Virtual Reality and collected data from 66 participants across genders and life stages through interviews, self-reported emotions, and physiological sensor data. Our findings revealed an acute lack of knowledge about self-body anatomy and a need for creating health literacy.</p>
          </div>
          
          <div class="publication-item">
            <h4><a href="#">Can we say a cat is a cat? Understanding the challenges in annotating physiological signal-based emotion data</a></h4>
            <p><em>PhysioCHI, CHI 2024 Workshop (June 2024)</em></p>
            <p><strong>Authors:</strong> Pragya Singh, Mohan Kumar, Pushpendra Singh</p>
            <p>This paper presents a position discussion on the current technique of annotating physiological signal-based emotion data. Our discourse underscores the importance of adopting a nuanced understanding of annotation processes, paving the way for a more insightful exploration of the intricate relationship between physiological signals and human emotions.</p>
          </div>
          
          <div class="publication-item">
            <h4><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150311">Generating Tiny Deep Neural Networks for ECG Classification on MicroControllers</a></h4>
            <p><em>IEEE International Conference on Pervasive Computing, PerCom Industry Track 2023 (March 2023)</em></p>
            <p><strong>Authors:</strong> S. Mukhopadhyay, S. Dey, A. Ghose, Pragya Singh and P. Dasgupta</p>
            <p>This paper shows that Neural Architecture Search (NAS) can be used to generate tiny but accurate multi-objective models for classifying ECG signals. Our framework is the first of its kind for automatically generating a DNN for screening Atrial Fibrillation on an MCU. Moreover, our research shows that the proposed NAS finds more accurate tiny models than human-designed ones and is effective in enabling customized solutions for a resource-limited target platform.</p>
          </div>
        </div>

      </div>
    </section><!-- End Publications Section -->
    
    <!-- ======= Awards Section ======= -->
    <section id="awards" class="services">
      <div class="container">

        <div class="section-title">
          <h2>Awards and Fellowships</h2>
        </div>

        <div class="row">
          <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up">
            <div class="icon"><i class="bi bi-award"></i></div>
            <h4 class="title">Chanakya Doctoral Fellowship</h4>
            <p class="description">From Ihub Anubhuti (August 2024)</p>
          </div>
          <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up" data-aos-delay="100">
            <div class="icon"><i class="bi bi-airplane"></i></div>
            <h4 class="title">Microsoft Conference Travel Grant</h4>
            <p class="description">For NeurIPS 2024 (September 2024)</p>
          </div>
          <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up" data-aos-delay="200">
            <div class="icon"><i class="bi bi-star"></i></div>
            <h4 class="title">Award Finalist</h4>
            <p class="description">For Poster Presentation at The Machine Learning Summer School in Okinawa 2024 (March 2024)</p>
          </div>
        </div>

      </div>
    </section><!-- End Awards Section -->

    <!-- ======= Contact Section ======= -->
    <section id="contact" class="contact">
      <div class="container">

        <div class="section-title">
          <h2>Contact</h2>
          <p>If our research interests align, I would be grateful to connect and collaborate on new ideas.</p>
        </div>

        <div class="row" data-aos="fade-in">

          <div class="col-lg-5 d-flex align-items-stretch">
            <div class="info">
              <div class="address">
                <i class="bi bi-geo-alt"></i>
                <h4>Location:</h4>
                <p>IIITD, Delhi, India</p>
              </div>

              <div class="email">
                <i class="bi bi-envelope"></i>
                <h4>Email:</h4>
                <p>pragyas@iiitd.ac.in</p>
                <p>pragyasingh18rathore@gmail.com</p>
              </div>
              
              <div class="phone">
                <i class="bi bi-phone"></i>
                <h4>Phone:</h4>
                <p>+91 8542017003</p>
              </div>

              <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d3504.8026265809!2d77.2709685!3d28.5456517!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x0%3A0x691393414902968e!2sIIIT-Delhi%20R%26D%20Building!5e0!3m2!1sen!2sin!4v1639315084076!5m2!1sen!2sin" frameborder="0" style="border:0; width: 100%; height: 290px;" allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </section><!-- End Contact Section -->
  </main><!-- End #main -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
